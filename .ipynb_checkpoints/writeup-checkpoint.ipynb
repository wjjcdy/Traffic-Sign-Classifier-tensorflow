{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "交通标志识别工程，其主要处理步骤如下：\n",
    "* 导入数据集\n",
    "* 查看数据集个数，类型，包括每种交通标志的图片和每种交通标志的个数；\n",
    "* 将数据集进行预处理，包括灰度转换、归一化等；\n",
    "* 设计训练模型\n",
    "* 采用训练数据集进行训练，并调整一定参数，验证准确到达一定阈值，保存模型参数；\n",
    "* 采用网上的5张德国交通标志进行预测；\n",
    "* 并分析预测的5张的softmax概率和准确度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Summary & Exploration\n",
    "\n",
    "#### 1. Provide a basic summary of the data set. In the code, the analysis should be done using python, numpy and/or pandas methods rather than hardcoding results manually.\n",
    "\n",
    "1. 本人采用python的库中“len”方法用于获取所有数据集的size；\n",
    "2. 采用numpy库中“shape”方法看查看每一张交通标志图片的形状；\n",
    "3. 为获取所有数据集中所有交通标志的种类，由于交通标志种类序列y_train中间存在大量重复，\n",
    "   因此采用python库中的\"set\"方法先将其转换set类型。由于set类型不允许其中元素重复，\n",
    "   因此会自动生成所有仅存唯一的交通标志类型，因此采用“len”方法获取的便是数据集中所有交通标志的个数；\n",
    "\n",
    "通过以上方法获取的结果如下：\n",
    "\n",
    "* The size of training set is 34799\n",
    "* The size of test set is 12630\n",
    "* The shape of a traffic sign image is (32, 32, 3)\n",
    "* The number of unique classes/labels in the data set is 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Include an exploratory visualization of the dataset.\n",
    "\n",
    "导入数据集，随机选择观测训练集中的图片，如下图为交通标志为“1”的图像，采用“plt.imshow”方法显示。\n",
    "\n",
    "![alt text](./examples/one_example.png \"一张交通标志图像\")\n",
    "\n",
    "初步观测整个数据集各个种类交通标志的分布情况，遍历整个43类交通标志，并采用mask方法，获取每种交通标志在训练数据集的集合。然后采用字典类型将关键字定为交通标志类型，而其对应值为交通标志个数。最后采用“plt.bar”画出每种交通标志对应的图像个数的分布；其示意图如下：\n",
    "\n",
    "![alt text](./examples/class_bar.png \"交通标志分布图\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design and Test a Model Architecture\n",
    "#### 交通标志图片预处理\n",
    "1. 由于观测数据集图像，发现每种交通标志的图像中的颜色并非主要特征，因此可以转化为灰度图像降低训练集图像大小；采用cv中的“cv2.cvtColor”。其一张图片处理结果示意图所示：\n",
    "![alt text](./examples/gray_example.png \"灰度处理示意图\")\n",
    "2. 归一化处理，主要使图像的中每个单元值在均值0分布。由于图片像素值范围为0~255，因此采用“pixel /255.0 - 0.5”方法归一化；\n",
    "\n",
    "3. 根据导入的数据集分布发现，原数据集个数较少，同时不同种类的图片的个数差距较大，容易导致欠拟合；因此我采用将原始图片旋转、平移的方法，进行增加假数据，增强数据集；主要是因为轻微的旋转和平移并不改变其交通标志的主要特征，因此极大地增加了数据个数；同时为了平均每种类型图片的个数基本相同，并设置个数Each_label_num（经后期的训练结果调整此数，目前我采用2500可满足作业要求），将每种类型的图片增加至设置值；\n",
    " *采用 “ndimage.rotate”对图片进行随机旋转，旋转角度控制在（-12,12），采用方法“np.random.randint”，旋转角度不能太大否则可导致特征发生变化；\n",
    " \n",
    " *采用“cv2.warpAffine”对图片进行随机上下左右平移，平移距离在（-2,2），同样是保证平移距离不能过大；\n",
    " \n",
    " *为保证最后每种交通标志图片的个数达到并设置个数Each_label_num，需要计算每种类型图片现有个数如class1的class1_num_curr，因此可获取还需要class1_fake_num = (Each_label_num  - class1_num_curr),如果class1_fake_num>0,表明需要增加假数据；其假数据产生希望更加随机性，因此可分为两部分：\n",
    " \n",
    "  (1).class1_fake_num对class1_num_curr取整为class1_multiple_num，表明class1中每张图片均经旋转、平移产生class1_multiple_num个假数据；\n",
    "  \n",
    "  (2).class1_fake_num对class1_num_curr取余为class1_another_num，表明class1中随机抽取class1_another_num个图片经旋转、平移各产生一个假数据；\n",
    " 4. 最后采用 “np.concatenate”将原数据集和假数据集进行合并形成新的数据集，作为新的训练数据集；\n",
    " \n",
    " 其中一原图像和对应的假数据示意图如图所示：\n",
    " ![alt text](./examples/fake_example.png \"假数据示意图\")\n",
    " \n",
    " 新的数据集每种交通标志个数分布如图所示：\n",
    "  \n",
    "![alt text](./examples/new_class_bar.png \"交通标志分布图\")\n",
    "\n",
    "从上图可看出，已制造出足够多的假数据，并且保证每种交通标志数据的个数基本相同；\n",
    "\n",
    "实际上，经过最后的训练结果对比发现灰度处理和归一化处理，训练结果并无明显改善；而仅采用增加假数据集可满足作业要求；因此我最终进入训练模型的数据集仅采用增加假数据后的3通道的彩色图像；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 训练模型\n",
    "\n",
    "基于交通标志复杂性，而且数据集的大小为32*32，因此可完全采用课程中提供的LeNet模型进行作为训练模型，我采用的数据为彩色数据，因此输入图像的深度为3；\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 3x3     \t| 5x5 stride, VALID padding, outputs 28x28x16 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x16 \t\t\t\t|\n",
    "| Convolution 3x3\t    | 5x5 stride, VALID padding, outputs 10x10x16   |\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 5x5x16 \t\t\t\t    |\n",
    "| Fully connected\t\t| outputs 120  \t\t\t\t\t\t\t\t\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 80  \t\t\t\t\t\t\t\t\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 43  \t\t\t\t\t\t\t\t\t|\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 训练过程\n",
    "1. 我采用“tf.nn.softmax_cross_entropy_with_logits”获取交叉熵cross_entropy作为损失函数去优化；\n",
    "\n",
    "2. 为提高验证集的准确率，训练时优化的学习率经过多次训练采用的值较小为 0.0005；\n",
    "\n",
    "3. 正因为设置的学习率较小，同时在不增加新数据的同时提高模型的准确率，因此必须经过多次训练满足要求，我目前设置的周期仅为20；主要因为训练时间过长，因此设置较小，但可满足作业要求；\n",
    "\n",
    "4. batch size我目前设置为课程中提供的一般推荐值128，由于内存有限，设置过大导致电脑较慢，128可满足需求；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.描述为满足验证准确率达到0.93的训练模型的方法\n",
    "\n",
    "我最后采用的是已知比较出名的结构：\n",
    "* 采用的是Lenet-5结构，是著名的手写体字符高效的卷积神经网络。\n",
    "* 之所以选择Lenet-5结构，包括以下原因：\n",
    "  1. 目前提供的交通标志数据集每个图像的大小刚好是32*32，完全和Lenet-5结构输入完全吻合；\n",
    "  2. 本作业是分类任务和Lenet-5结果吻合；\n",
    "  3. 课程中提供了Lenet-5结构模型和详细解释，并且完成了手写字的识别的练习，比较熟悉；\n",
    "  4. Lenet-5共包含了7层结构，结构简单，但是全包括了深度学习中的最基本的应有的处理模块，包括：卷积神经网络层、全连接层、池化层、RELU激活。而且每层的隐含神经单元不多，同时提供的交通标志训练数据集数量的并不庞大，过拟合的难以出现，因此dropout操纵并不是十分必要；\n",
    "  \n",
    "  从以上4点，我最后选择了标准的Lenet-5结构；\n",
    "  \n",
    "* 即使采用Lenet-5结构，我也通过调整图像的预处理、调节学习率等多个参数，包括：\n",
    "  1. 我采用和手写字一样的灰度图像作为输入，是由于经观察所有的交通标志图片，发现颜色并非其分类的主要特征；\n",
    "  2. 我同样采用3通道的彩色数据进行作为输入，则需要修改Lenet-5的输入图像层数为3；\n",
    "  3. 最后一层输出的层数，即分类应为交通标志的种类43；\n",
    "  4. 然后通过调节学习率、权重和偏移初始化分布、训练周期、batch_size等参数多次修改，进行训练；\n",
    "  \n",
    "  通过多次实验训练，我最终采用3通道的彩色图像进行训练和训练过程中设置的参数，最后模型的精确度如下：\n",
    "  * training set accuracy of ?\n",
    "  * validation set accuracy of ? \n",
    "  * test set accuracy of ?\n",
    "  \n",
    "  模型训练准确度满足作业要求\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Model on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Choose five German traffic signs found on the web and provide them in the report. For each image, discuss what quality or qualities might be difficult to classify.\n",
    "\n",
    "Here are five German traffic signs that I found on the web:\n",
    "\n",
    "![alt text](./examples/new_class_bar.png \"交通标志分布图\")\n",
    "\n",
    "The first image might be difficult to classify because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Discuss the model's predictions on these new traffic signs and compare the results to predicting on the test set. At a minimum, discuss what the predictions were, the accuracy on these new predictions, and compare the accuracy to the accuracy on the test set (OPTIONAL: Discuss the results in more detail as described in the \"Stand Out Suggestions\" part of the rubric).\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Stop Sign      \t\t| Stop sign   \t\t\t\t\t\t\t\t\t| \n",
    "| U-turn     \t\t\t| U-turn \t\t\t\t\t\t\t\t\t\t|\n",
    "| Yield\t\t\t\t\t| Yield\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| 100 km/h\t      \t\t| Bumpy Road\t\t\t\t\t \t\t\t\t|\n",
    "| Slippery Road\t\t\t| Slippery Road      \t\t\t\t\t\t\t|\n",
    "The model was able to correctly guess 4 of the 5 traffic signs, which gives an accuracy of 80%. This compares favorably to the accuracy on the test set of ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Describe how certain the model is when predicting on each of the five new images by looking at the softmax probabilities for each prediction. Provide the top 5 softmax probabilities for each image along with the sign type of each probability. (OPTIONAL: as described in the \"Stand Out Suggestions\" part of the rubric, visualizations can also be provided such as bar charts)\n",
    "\n",
    "The code for making predictions on my final model is located in the 11th cell of the Ipython notebook.\n",
    "\n",
    "For the first image, the model is relatively sure that this is a stop sign (probability of 0.6), and the image does contain a stop sign. The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| .60         \t\t\t| Stop sign   \t\t\t\t\t\t\t\t\t| \n",
    "| .20     \t\t\t\t| U-turn \t\t\t\t\t\t\t\t\t\t|\n",
    "| .05\t\t\t\t\t| Yield\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| .04\t      \t\t\t| Bumpy Road\t\t\t\t\t \t\t\t\t|\n",
    "| .01\t\t\t\t    | Slippery Road      \t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "For the second image ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用滑窗获取车道线大致位置的思想如下：\n",
    "* 在提取的车道线特征图（如下图）可明显看出，车道线主要沿垂直方向分布，因此可以将图像以垂直方向进行统计特征点个数，并画直方图，如图所示，显然其中的两个波峰便是左右车道线在水平方向，即x轴的位置；\n",
    "![alt text](./output_images/车道线特征图.png \"三种特征组合提取车道线\")\n",
    "![alt text](./output_images/直方图.png \"垂直方向特征点个数统计\")\n",
    "* 由于车道线毕竟不一定完全垂直，为更精确获取车道线特征点在x轴方向分布，可将图片沿垂直方向等间隔采样，我将其等分为9份；可求每一份的直方图波峰，即为每段车道线大约位置；\n",
    "* 由于特征点存在一定噪点，因此每一份直方图波峰并不一定完全准确；考虑到一张图片中的车道线应是连续的，且宽度具有一定范围，可采用此条件限制求取直方图的更精确的范围；\n",
    "* 假设已知图片底部作为第一份，其车道线在x轴方向的位置，并设置左右范围和其上下边界可组成一个矩形框，其中矩形框内的特征点可认为为车道线特征点，并统计其特征点在x轴的主要分布，作为下个相邻的一份其车道线在X轴方向的位置；\n",
    "* 按照上一步骤以此计算完9份即9个矩形框中所有的特征点；\n",
    "\n",
    "依据以上滑窗思想，获取车道线特征点代码参考\"./work.ipynb\"中的in24步骤，具体操纵步骤如下：\n",
    "\n",
    "1. 求取最底部的一份左右车道线在x轴方向大约位置；并且为提高可靠性，并降低错误点，首先采用图片底部的一半的图片求取直方图，获取到两个波峰的位置，即为左右车道线第一份特征点主要位置；\n",
    "2. 将图片在垂直方向等分9份，确定每一份的垂直方向边界；\n",
    "3. 设置车道线中心位置左右分布范围边界；\n",
    "4. 分别记录所有矩形框内所有特征点；\n",
    "5. 分布统计左右矩形框内特征点个数，并判断其个数是否超出阈值；若超出阈值则更新其车道线中心位置；\n",
    "6. 更新垂直方向上的边界；\n",
    "7. 重复3～6步骤，直到9份全部计算结束；\n",
    "8. 获取整个图片中左右车道线特征点坐标。\n",
    "其获取图片左右车道线特征点示意图如图所示，其中左右特征点用颜色区分。\n",
    "![alt text](./output_images/左右车道线主要特征点.png \"左右车道线主要特征点\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 还原至原观测角度方向并显示在原图片上\n",
    "经过视角转换成鸟瞰图，从而检测出的左右车道线的坐标位置，其坐标也是鸟瞰图视角下的，因此需要还原至原始视角的图片上。其代码参考 \"./work.ipynb\"中的in36步骤。\n",
    "1. 首先依据左右车道线上的坐标集合，并采用教程中提供的“cv2.fillPoly”方法构建一份车道线覆盖区域的图片；\n",
    "2. 将鸟瞰图片采用\"./work.ipynb\"中的in10中方法，反向转换回原来视角图片（即将视角转换成鸟瞰图步骤中的src和dst的4组坐标调换）。\n",
    "3. 采用‘cv2.addWeighted’方法将原图与车道线覆盖区域图融合；\n",
    "\n",
    "其结果图如图所示：\n",
    "![alt text](./output_images/输出结果.png \"车道线检测结果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取车道线上主要特征点另一种方法\n",
    "\n",
    "采用动态滑窗方法，相当于遍历整个图像，如果是一张单独照片，需要如此方法，但是由于汽车观测的视频相邻的两帧照片区别不大，因此车道线的位置不会有太大的变化。可以采用如此可以用上一帧的计算的车道线多项式，然后直接扩展出有效车道线范围内，进行查找新的一帧车道线的点。如此相对于每次遍历整张图片每个窗口，效率有较大提高。\n",
    "\n",
    "其代码参考\"./work.ipynb\"中的in32步骤，其执行步骤如下：\n",
    "1. 设置车道线中心左右范围； \n",
    "2. 根据已知左右车道线多项式方程，分别求出每个y轴方向对应x的坐标；\n",
    "3. 统计在此y轴上对应x有效范围内的特征点；\n",
    "4. 统计所有左右车道线特征点坐标；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 曲率\n",
    "由于车道线采用多项式拟合，因此可根据多项式表达式，求出其曲率。\n",
    "其多项式为\n",
    "$ f(y) = Ay^2+By+C\\text {，多项式} $。\n",
    "\n",
    "则曲率为\n",
    "$ R = \\frac{[1+(\\frac{dx}{dy})^2]^3/2}{|\\frac{d^2x}{dy^2}|}\\text {，曲率} $。\n",
    "\n",
    "化简可得\n",
    "$ R = \\frac{[1+(2Ay + B)^2]^3/2}{|2A|}\\text {，曲率} $。\n",
    "\n",
    "其中y应当取图像最底部的值，因为离车最近，才是汽车目前所在位置的车道线曲率，其中y=img.shape[0]\n",
    "\n",
    "由于目前计算的曲率是以图片像素单位计算的，但在真实环境下的曲率应当根据像素对应实际对应的距离进行换算。从上图中实际车道线的宽度和长度，以及参考教学课件可知。可近似认为车道宽度为3.7m，对应像素个数约为550; 车道长度为30m，对应车道线为720像素点。应将图片中车道线上点像素坐标转换为真实坐标，然后进行再曲线拟合并曲率计算；其代码参考为 \"./work.ipynb\"中的in34函数；\n",
    "\n",
    "### 偏移量\n",
    "由于假设摄像机安装位置在汽车中心，因此图像的中心线则为汽车中心，而图像中心距离左右车道线中心的位置则为汽车偏移量。因此可先根据真实环境的多项式求出左右车道线在图片底部的x轴坐标和图片中心对应真实环境坐标的x轴，其代码参考 \"./work.ipynb\"中的in34步骤中最后3行代码；其中偏移量offset为正，表明汽车向右偏移，否则向左偏移；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用视频进行车道线检测\n",
    "* 采用‘cv2.VideoCapture’获取project_video中每一帧图片，进行上述的pipeline处理并输出车道线覆盖区域与原图融合的图片；\n",
    "* 同时为提高处理速度，视频中第一帧图片采用滑窗方法获取左右车道线特征点范围提取，而接下来每一帧采用上帧的车道线结果提取本帧图片车道线特征点范围，获取车道线多项式。\n",
    "* 计算每一张图片中左右车道线的曲率和汽车的偏离量，并将其值采用‘cv2.putText’打印至图片上;\n",
    "* 将每一帧的结果图片采用‘cv2.VideoWriter’保存视频。\n",
    "以上操作步骤，其代码参考 \"./work.ipynb\"中的步骤in41。其输出处理后的视频链接\n",
    "[link to my video result](./output_images/project_video1.mp4)\n",
    "\n",
    "（如不能播放，请到作业文件下的output_images/project_video1.mp4进行播放。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 讨论\n",
    "本次作业的采用的技术和方法，基本全部参考教学视频提供的方法。其中整个车道线检测过程中，车道线特征点提取这一环节为认为最为复杂和灵活性较高，不同的提取方案如梯度法、色彩空间等，都有一定优点和缺点，因此需要配合使用互相弥补其缺点。\n",
    "即使融合多种方法，但每种方法中的均有相关参数需要调节，每个参数都需要设置合理，则车道线才能被稳定检测出来；\n",
    "由于我目前虽然采用梯度法、色彩空间中的饱和度和颜色三种检测方法，但其参数是根据提供参考图片多次尝试获取的，且是固定的，因此稳定性稍差。因此在有阴影或图片过亮或过案时，仍然存在检测错误的可能；\n",
    "本人认为，需要收集更多的不同情况下车道线照片，分别尝试获取对应的参数，而后续的车道线特征点检测时每种方法的参数也应根据图片的环境情况，进行动态调整参数，则检测能力会更加稳定；\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
